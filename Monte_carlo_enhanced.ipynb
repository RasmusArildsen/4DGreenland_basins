{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02052d03",
   "metadata": {},
   "source": [
    "# Monte Carlo perturbations of DEM and basin delineation\n",
    "\n",
    "This notebook documents how we generate and analyse an **ensemble of hydrological basin maps**\n",
    "by perturbing the input DEM according to its elevation uncertainty.\n",
    "\n",
    "The goals are to:\n",
    "\n",
    "1. Sample many realisations of the DEM using its variance/standard‚Äëdeviation raster.\n",
    "2. For each realisation, run the full GRASS hydrological workflow to obtain a basin map.\n",
    "3. Derive **pixelwise** and **basinwise** stability metrics that tell us where basin boundaries\n",
    "   are robust and where they are uncertain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d4186",
   "metadata": {},
   "source": [
    "## 1. Configure DEM, uncertainty and GRASS environment\n",
    "\n",
    "This cell:\n",
    "\n",
    "- Defines paths to the DEM (`PRODEM19_dem.tif`) and its variance / uncertainty raster.\n",
    "- Sets the number of Monte Carlo realisations `N_MC` and the stream extraction threshold.\n",
    "- Sets up a GRASS location (via QGIS) and imports the DEM and ice mask.\n",
    "- For each Monte Carlo run:\n",
    "\n",
    "  * Draws a random perturbation field consistent with the DEM uncertainty.\n",
    "  * Adds it to the DEM to create a perturbed DEM realisation.\n",
    "  * Runs the hydrological workflow (flow routing, stream extraction, `r.stream.basins`).\n",
    "  * Writes the resulting basin map to `basins_mc_XXX.tif` in the output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31338c4e-50a5-40a0-9d60-c6f31a023dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using existing GRASS location: C:\\Users\\s174035\\Documents\\grassdata\\dem_loc\n",
      "üåø GRASS session initialized in:\n",
      "   C:\\Users\\s174035\\Documents\\grassdata\\dem_loc\\PERMANENT\n",
      "\n",
      "GISDBASE='C:\\Users\\s174035\\Documents\\grassdata';\n",
      "LOCATION_NAME='dem_loc';\n",
      "MAPSET='PERMANENT';\n",
      "\n",
      "‚úì r.in.gdal ‚Üí dem\n",
      "‚úì r.in.gdal ‚Üí dem_var\n",
      "GRASS 8.4.1 (2025)\n",
      "\n",
      "‚úì Addon available: r.stream.extract\n",
      "‚úì Addon available: r.stream.basins\n",
      "GISDBASE='C:\\Users\\s174035\\Documents\\grassdata';\n",
      "LOCATION_NAME='dem_loc';\n",
      "MAPSET='PERMANENT';\n",
      "\n",
      "ADDON_BASE: C:\\Users\\s174035\\AppData\\Roaming\\GRASS8\\addons\n",
      "PATH contains addon_bin? True\n",
      "PATH contains addon_scripts? True\n",
      "‚úì Filled internal DEM holes ‚Üí dem_filled\n",
      "‚úì Ice mask imported and rasterized ‚Üí ice_mask_rast\n",
      "\n",
      "==================== Monte Carlo Run 001/2 ====================\n",
      "‚úì Created perturbation: pert_mc_001\n",
      "‚úì Created perturbed DEM: dem_mc_001\n",
      "‚úì Mask set from ice_mask_rast\n",
      "‚úì basins_ref created from reference run\n",
      "‚úì Initialised basin_match_sum from reference basins\n",
      "üì§ Exporting basins_001 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/basins_mc_001.tif\n",
      "üì§ Exporting accum_001 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/accum_mc_001.tif\n",
      "üì§ Exporting flow_dir_001 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/flowdir_mc_001.tif\n",
      "üì§ Exporting streams_001 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/streams_mc_001.tif\n",
      "üì§ Exporting pert_mc_001 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/perturbation_mc_001.tif\n",
      "‚úÖ Finished Monte Carlo hydrology for run 001\n",
      "\n",
      "==================== Monte Carlo Run 002/2 ====================\n",
      "‚úì Created perturbation: pert_mc_002\n",
      "‚úì Created perturbed DEM: dem_mc_002\n",
      "‚úì Mask set from ice_mask_rast\n",
      "‚úì Updated basin_match_sum for run 002\n",
      "üì§ Exporting basins_002 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/basins_mc_002.tif\n",
      "üì§ Exporting accum_002 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/accum_mc_002.tif\n",
      "üì§ Exporting flow_dir_002 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/flowdir_mc_002.tif\n",
      "üì§ Exporting streams_002 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/streams_mc_002.tif\n",
      "üì§ Exporting pert_mc_002 ‚Üí E:/Rasmus/DTU/Cryo/4DGreenland/Basins_serious/prodem_19_MC2/perturbation_mc_002.tif\n",
      "‚úÖ Finished Monte Carlo hydrology for run 002\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# USER SETTINGS\n",
    "# =============================================================================\n",
    "DEM      = r\"E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\DEM\\PRODEM19_dem.tif\"\n",
    "VAR      = r\"E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\DEM\\prodem19_var.tif\"  # variance (œÉ¬≤ or œÉ, see note below)\n",
    "ice_mask = r\"E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\Ice_mask\\02-PROMICE-2022-IceMask-polygon.gpkg\"\n",
    "OUT      = r\"E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\Basins_serious\\prodem_19_MC2\"\n",
    "\n",
    "QGIS_PREFIX      = r\"C:\\Program Files\\QGIS 3.40.11\"\n",
    "STREAM_THRESHOLD = 500   # stream extraction threshold\n",
    "N_MC             = 2    # number of Monte Carlo realisations\n",
    "CORR_PIX         = 5     # correlation length in pixels for Gaussian kernel\n",
    "REF_RUN          = 1     # reference realisation for basin stability\n",
    "STABLE_SUM_MAP   = \"basin_match_sum\"  # internal GRASS raster for stability count\n",
    "CERT_THRESH      = 0.9   # certainty threshold for \"core\" basins\n",
    "\n",
    "Path(OUT).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# GRASS ENVIRONMENT INIT\n",
    "# =============================================================================\n",
    "GISBASE = fr\"{QGIS_PREFIX}\\apps\\grass\\grass84\"\n",
    "os.environ.update({\n",
    "    \"GISBASE\": GISBASE,\n",
    "    \"GRASS_PYTHON\": sys.executable,\n",
    "    \"PROJ_LIB\": fr\"{QGIS_PREFIX}\\share\\proj\",\n",
    "    \"GDAL_DATA\": fr\"{QGIS_PREFIX}\\share\\gdal\",\n",
    "})\n",
    "\n",
    "os.environ[\"PATH\"] = os.pathsep.join([\n",
    "    fr\"{GISBASE}\\bin\",\n",
    "    fr\"{GISBASE}\\extrabin\",\n",
    "    fr\"{QGIS_PREFIX}\\bin\",\n",
    "    fr\"{QGIS_PREFIX}\\apps\\Qt5\\bin\",\n",
    "    os.environ[\"PATH\"],\n",
    "])\n",
    "\n",
    "sys.path.insert(0, fr\"{GISBASE}\\etc\\python\")\n",
    "\n",
    "import grass.script as gs\n",
    "import grass.script.setup as gsetup\n",
    "from grass.script.core import find_program, CalledModuleError\n",
    "\n",
    "# =============================================================================\n",
    "# HELPERS\n",
    "# =============================================================================\n",
    "def start_grass_from_raster(raster_path, location=\"dem_loc\", mapset=\"PERMANENT\"):\n",
    "    \"\"\"Start GRASS in ~/Documents/grassdata based on a DEM.\"\"\"\n",
    "    gisdbase = Path.home() / \"Documents\" / \"grassdata\"\n",
    "    gisdbase.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    loc_path = gisdbase / location\n",
    "    mapset_path = loc_path / mapset\n",
    "\n",
    "    if not loc_path.exists():\n",
    "        print(f\"üìÅ Creating new GRASS location: {loc_path}\")\n",
    "        gs.core.create_location(\n",
    "            dbase=str(gisdbase),\n",
    "            location=location,\n",
    "            filename=raster_path,\n",
    "            overwrite=True\n",
    "        )\n",
    "    else:\n",
    "        print(f\"‚úÖ Using existing GRASS location: {loc_path}\")\n",
    "\n",
    "    gsetup.init(str(mapset_path))\n",
    "    print(f\"üåø GRASS session initialized in:\\n   {mapset_path}\\n\")\n",
    "    print(gs.read_command(\"g.gisenv\"))\n",
    "\n",
    "    return str(gisdbase), location, mapset\n",
    "\n",
    "\n",
    "def import_dem_native(input_path, out_name=\"dem\"):\n",
    "    \"\"\"Import or clone DEM to a native GRASS raster.\"\"\"\n",
    "    raster = input_path.replace(\"\\\\\", \"/\")\n",
    "    try:\n",
    "        gs.run_command(\n",
    "            \"r.in.gdal\",\n",
    "            input=raster,\n",
    "            output=out_name,\n",
    "            flags=\"o\",\n",
    "            overwrite=True\n",
    "        )\n",
    "        print(f\"‚úì r.in.gdal ‚Üí {out_name}\")\n",
    "    except Exception:\n",
    "        gs.run_command(\n",
    "            \"r.external\",\n",
    "            input=raster,\n",
    "            output=f\"{out_name}_ext\",\n",
    "            flags=\"o\",\n",
    "            overwrite=True\n",
    "        )\n",
    "        gs.run_command(\"g.region\", raster=f\"{out_name}_ext\")\n",
    "        gs.mapcalc(f\"{out_name} = {out_name}_ext * 1.0\", overwrite=True)\n",
    "        print(f\"‚úì r.external + clone ‚Üí {out_name}\")\n",
    "    gs.run_command(\"g.region\", raster=out_name)\n",
    "\n",
    "\n",
    "def safe(expr: str):\n",
    "    \"\"\"Convenience wrapper for r.mapcalc with error reporting.\"\"\"\n",
    "    try:\n",
    "        gs.run_command(\"r.mapcalc\", expression=expr, overwrite=True)\n",
    "    except CalledModuleError as e:\n",
    "        raise RuntimeError(f\"Mapcalc failed: {expr}\\n{e}\")\n",
    "\n",
    "\n",
    "def ensure_grass_addon(module_name: str):\n",
    "    \"\"\"Install a GRASS addon if missing.\"\"\"\n",
    "    if find_program(module_name) is None:\n",
    "        gs.run_command(\n",
    "            \"g.extension\",\n",
    "            extension=module_name,\n",
    "            operation=\"add\",\n",
    "            flags=\"f\"\n",
    "        )\n",
    "        if find_program(module_name) is None:\n",
    "            raise RuntimeError(f\"Failed to install GRASS addon: {module_name}\")\n",
    "    print(f\"‚úì Addon available: {module_name}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# START GRASS AND IMPORT DEM + VARIANCE\n",
    "# =============================================================================\n",
    "GISDBASE, LOCATION, MAPSET = start_grass_from_raster(DEM)\n",
    "import_dem_native(DEM, out_name=\"dem\")\n",
    "import_dem_native(VAR, out_name=\"dem_var\")\n",
    "print(gs.read_command(\"g.version\"))\n",
    "\n",
    "# =============================================================================\n",
    "# GRASS ADDON HANDLING\n",
    "# =============================================================================\n",
    "APPDATA = os.environ.get(\"APPDATA\", str(Path.home()))\n",
    "addon_base = Path(APPDATA) / \"GRASS8\" / \"addons\"\n",
    "os.environ[\"GRASS_ADDON_BASE\"] = str(addon_base)\n",
    "\n",
    "addon_bin = addon_base / \"bin\"\n",
    "addon_scripts = addon_base / \"scripts\"\n",
    "\n",
    "os.environ[\"PATH\"] = os.pathsep.join([\n",
    "    str(addon_bin),\n",
    "    str(addon_scripts),\n",
    "    os.environ[\"PATH\"]\n",
    "])\n",
    "os.environ[\"GRASS_ADDON_PATH\"] = os.pathsep.join([str(addon_bin), str(addon_scripts)])\n",
    "\n",
    "ensure_grass_addon(\"r.stream.extract\")\n",
    "ensure_grass_addon(\"r.stream.basins\")\n",
    "\n",
    "print(gs.read_command(\"g.gisenv\"))\n",
    "print(\"ADDON_BASE:\", os.environ[\"GRASS_ADDON_BASE\"])\n",
    "print(\"PATH contains addon_bin?\", str(addon_bin) in os.environ[\"PATH\"])\n",
    "print(\"PATH contains addon_scripts?\", str(addon_scripts) in os.environ[\"PATH\"])\n",
    "\n",
    "# make sure no mask is active initially\n",
    "try:\n",
    "    gs.run_command(\"r.mask\", flags=\"r\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =============================================================================\n",
    "# FILL ONLY INTERNAL HOLES IN DEM (ONCE, WITHOUT MASK)\n",
    "# =============================================================================\n",
    "gs.run_command(\"g.region\", raster=\"dem\")\n",
    "gs.run_command(\n",
    "    \"r.fillnulls\",\n",
    "    input=\"dem\",\n",
    "    output=\"dem_filled\",\n",
    "    method=\"bilinear\",\n",
    "    overwrite=True\n",
    ")\n",
    "print(\"‚úì Filled internal DEM holes ‚Üí dem_filled\")\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORT ICE MASK ONCE AND RASTERIZE\n",
    "# =============================================================================\n",
    "gs.run_command(\n",
    "    \"v.import\",\n",
    "    input=ice_mask.replace(\"\\\\\", \"/\"),\n",
    "    output=\"ice_mask_vec\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "gs.run_command(\"g.region\", raster=\"dem_filled\")\n",
    "gs.run_command(\n",
    "    \"v.to.rast\",\n",
    "    input=\"ice_mask_vec\",\n",
    "    output=\"ice_mask_rast\",\n",
    "    use=\"val\",\n",
    "    value=1,\n",
    "    overwrite=True\n",
    ")\n",
    "print(\"‚úì Ice mask imported and rasterized ‚Üí ice_mask_rast\")\n",
    "\n",
    "# =============================================================================\n",
    "# MONTE CARLO HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "def make_perturbed_dem(run_idx,\n",
    "                       base_dem=\"dem_filled\",\n",
    "                       var_map=\"dem_var\",\n",
    "                       corr_pix=CORR_PIX):\n",
    "    \"\"\"\n",
    "    Create a spatially correlated random perturbation and add it to the DEM.\n",
    "    Uses a Gaussian kernel with correlation length specified in pixels.\n",
    "\n",
    "    Assumes var_map contains variance (œÉ¬≤). If it contains œÉ instead, replace\n",
    "    sqrt(var_map) with var_map in the perturbation expression.\n",
    "    \"\"\"\n",
    "    # ensure no mask is active while generating noise / perturbation\n",
    "    try:\n",
    "        gs.run_command(\"r.mask\", flags=\"r\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # region aligned to DEM\n",
    "    gs.run_command(\"g.region\", raster=base_dem)\n",
    "\n",
    "    # 1) Gaussian white noise N(0,1)\n",
    "    noise_raw = \"noise_raw\"\n",
    "    gs.run_command(\n",
    "        \"r.surf.gauss\",\n",
    "        output=noise_raw,\n",
    "        mean=0.0,\n",
    "        sigma=1.0,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # 2) Impose spatial correlation with Gaussian kernel (corr_pix in cells)\n",
    "    reg = gs.parse_command(\"g.region\", flags=\"g\")\n",
    "    cellsize = float(reg[\"ewres\"])  # assume square-ish pixels\n",
    "\n",
    "    radius1 = corr_pix * cellsize          # in map units\n",
    "    radius2 = 2 * corr_pix * cellsize      # in map units\n",
    "\n",
    "    noise_corr = \"noise_corr\"\n",
    "    gs.run_command(\n",
    "        \"r.resamp.filter\",\n",
    "        input=noise_raw,\n",
    "        output=noise_corr,\n",
    "        filter=\"gauss,box\",\n",
    "        radius=f\"{radius1},{radius2}\",\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # 3) Build perturbation and perturbed DEM\n",
    "    out_dem  = f\"dem_mc_{run_idx:03d}\"\n",
    "    pert_map = f\"pert_mc_{run_idx:03d}\"\n",
    "\n",
    "    # If VAR is actually œÉ (std dev), change sqrt({var_map}) ‚Üí {var_map}\n",
    "    safe(\n",
    "        f\"{pert_map} = if(isnull({base_dem}) || isnull({var_map}), \"\n",
    "        f\"null(), float(noise_corr * sqrt({var_map})))\"\n",
    "    )\n",
    "\n",
    "    safe(\n",
    "        f\"{out_dem} = if(isnull({base_dem}), null(), {base_dem} + {pert_map})\"\n",
    "    )\n",
    "\n",
    "    print(f\"‚úì Created perturbation: {pert_map}\")\n",
    "    print(f\"‚úì Created perturbed DEM: {out_dem}\")\n",
    "\n",
    "    return out_dem\n",
    "\n",
    "\n",
    "def run_hydro_for_dem(dem_name, run_idx):\n",
    "    \"\"\"\n",
    "    Run neighbors ‚Üí fillnulls ‚Üí watershed ‚Üí streams ‚Üí basins\n",
    "    for a given DEM and export rasters with run-specific filenames.\n",
    "    Also updates the basin stability accumulator relative to REF_RUN.\n",
    "    \"\"\"\n",
    "    # Region to DEM\n",
    "    gs.run_command(\"g.region\", raster=dem_name, flags=\"p\")\n",
    "\n",
    "    # Apply ice mask (now DEM is clean; we don't fill based on mask)\n",
    "    gs.run_command(\"r.mask\", raster=\"ice_mask_rast\", overwrite=True)\n",
    "    print(\"‚úì Mask set from ice_mask_rast\")\n",
    "\n",
    "    # Smooth and fill any residual NULLs (inside mask)\n",
    "    gs.run_command(\n",
    "        \"r.neighbors\",\n",
    "        input=dem_name,\n",
    "        output=\"dem_smoothed_raw\",\n",
    "        method=\"average\",\n",
    "        size=3,\n",
    "        memory=300,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    gs.run_command(\n",
    "        \"r.fillnulls\",\n",
    "        input=\"dem_smoothed_raw\",\n",
    "        output=\"dem_smoothed\",\n",
    "        method=\"bilinear\",\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # Hydrology module outputs\n",
    "    accum    = f\"accum_{run_idx:03d}\"\n",
    "    flow_dir = f\"flow_dir_{run_idx:03d}\"\n",
    "    streams  = f\"streams_{run_idx:03d}\"\n",
    "    basins   = f\"basins_{run_idx:03d}\"\n",
    "    pert_map = f\"pert_mc_{run_idx:03d}\"  # created in make_perturbed_dem\n",
    "\n",
    "    # Watershed (D8)\n",
    "    gs.run_command(\n",
    "        \"r.watershed\",\n",
    "        elevation=\"dem_smoothed\",\n",
    "        accumulation=accum,\n",
    "        drainage=flow_dir,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # Extract streams\n",
    "    gs.run_command(\n",
    "        \"r.stream.extract\",\n",
    "        elevation=\"dem_smoothed\",\n",
    "        direction=flow_dir,\n",
    "        accumulation=accum,\n",
    "        threshold=STREAM_THRESHOLD,\n",
    "        stream_raster=streams,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # Basins\n",
    "    gs.run_command(\n",
    "        \"r.stream.basins\",\n",
    "        direction=flow_dir,\n",
    "        stream_rast=streams,\n",
    "        basins=basins,\n",
    "        flags=\"l\",\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Basin stability accumulator relative to reference run\n",
    "    # -------------------------------------------------------------------------\n",
    "    if run_idx == REF_RUN:\n",
    "        # Create a dedicated reference copy\n",
    "        gs.run_command(\"g.copy\", raster=[f\"{basins},basins_ref\"], overwrite=True)\n",
    "        print(\"‚úì basins_ref created from reference run\")\n",
    "\n",
    "        # Initialise stability sum: this pixel matches itself in the ref run\n",
    "        safe(f\"{STABLE_SUM_MAP} = if(!isnull(basins_ref), 1, null())\")\n",
    "        print(f\"‚úì Initialised {STABLE_SUM_MAP} from reference basins\")\n",
    "    else:\n",
    "        # Update stability sum: add 1 where this run's basin matches basins_ref\n",
    "        expr = (\n",
    "            f\"{STABLE_SUM_MAP} = \"\n",
    "            f\"if(!isnull(basins_ref) && !isnull({basins}) && {basins} == basins_ref, \"\n",
    "            f\"{STABLE_SUM_MAP} + 1, {STABLE_SUM_MAP})\"\n",
    "        )\n",
    "        safe(expr)\n",
    "        print(f\"‚úì Updated {STABLE_SUM_MAP} for run {run_idx:03d}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Export rasters for this realisation\n",
    "    # -------------------------------------------------------------------------\n",
    "    exports = [\n",
    "        (basins,    fr\"{OUT}\\basins_mc_{run_idx:03d}.tif\",       \"Int32\"),\n",
    "        (accum,     fr\"{OUT}\\accum_mc_{run_idx:03d}.tif\",        \"Float64\"),\n",
    "        (flow_dir,  fr\"{OUT}\\flowdir_mc_{run_idx:03d}.tif\",      \"Int32\"),\n",
    "        (streams,   fr\"{OUT}\\streams_mc_{run_idx:03d}.tif\",      \"Int16\"),\n",
    "        (pert_map,  fr\"{OUT}\\perturbation_mc_{run_idx:03d}.tif\", \"Float32\"),\n",
    "    ]\n",
    "\n",
    "    for name, fn, dtype in exports:\n",
    "        fn_norm = fn.replace(\"\\\\\", \"/\")\n",
    "        try:\n",
    "            info = gs.read_command(\"r.info\", map=name)\n",
    "            if \"min =\" in info and \"max =\" in info:\n",
    "                print(f\"üì§ Exporting {name} ‚Üí {fn_norm}\")\n",
    "\n",
    "                if name.startswith(\"pert_mc_\"):\n",
    "                    # For perturbation maps, be more lenient: let r.out.gdal\n",
    "                    # choose type/nodata based on the GRASS raster.\n",
    "                    gs.run_command(\n",
    "                        \"r.out.gdal\",\n",
    "                        input=name,\n",
    "                        output=fn_norm,\n",
    "                        format=\"GTiff\",\n",
    "                        createopt=\"COMPRESS=LZW,TILED=YES,BIGTIFF=YES\",\n",
    "                        overwrite=True\n",
    "                    )\n",
    "                else:\n",
    "                    # For all the other rasters, keep explicit types/nodata\n",
    "                    gs.run_command(\n",
    "                        \"r.out.gdal\",\n",
    "                        input=name,\n",
    "                        output=fn_norm,\n",
    "                        format=\"GTiff\",\n",
    "                        type=dtype,\n",
    "                        createopt=\"COMPRESS=LZW,TILED=YES,BIGTIFF=YES\",\n",
    "                        nodata=-9999,\n",
    "                        overwrite=True\n",
    "                    )\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Skipping {name}: no data detected.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to export {name}: {e}\")\n",
    "\n",
    "    # clear mask for safety before next realisation's perturbation\n",
    "    try:\n",
    "        gs.run_command(\"r.mask\", flags=\"r\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"‚úÖ Finished Monte Carlo hydrology for run {run_idx:03d}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MONTE CARLO LOOP\n",
    "# =============================================================================\n",
    "for i in range(1, N_MC + 1):\n",
    "    print(f\"\\n==================== Monte Carlo Run {i:03d}/{N_MC} ====================\")\n",
    "    dem_mc = make_perturbed_dem(\n",
    "        run_idx=i,\n",
    "        base_dem=\"dem_filled\",\n",
    "        var_map=\"dem_var\",\n",
    "        corr_pix=CORR_PIX,\n",
    "    )\n",
    "    run_hydro_for_dem(dem_mc, i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41769b",
   "metadata": {},
   "source": [
    "## 2. Pixelwise basin stability (all realisations on common grid)\n",
    "\n",
    "This cell:\n",
    "\n",
    "- Collects all `basins_mc_*.tif` realisations.\n",
    "- Reprojects / resamples them to the grid of a chosen reference realisation.\n",
    "- For each pixel, counts how often the **same basin label** appears across all runs.\n",
    "- Computes a **pixelwise certainty map**:\n",
    "\n",
    "  * `certainty(x) = n_max(x) / N`, where `n_max(x)` is the number of runs where\n",
    "    the most frequent basin label occurs at pixel `x`.\n",
    "  * High values (near 1) indicate very stable membership; low values highlight\n",
    "    pixels near uncertain divides.\n",
    "\n",
    "- Optionally defines a **core basin mask**, where certainty exceeds a chosen threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d007f9-0556-468a-bfb5-c166f9eded9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 basin realisations\n",
      "\n",
      "=== Comparing run 2/38: basins_mc_002.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:39<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 3/38: basins_mc_003.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:36<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 4/38: basins_mc_004.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 5/38: basins_mc_005.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:38<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 6/38: basins_mc_006.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:36<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 7/38: basins_mc_007.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:41<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 8/38: basins_mc_008.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:36<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 9/38: basins_mc_009.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:45<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 10/38: basins_mc_010.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 11/38: basins_mc_011.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:34<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 12/38: basins_mc_012.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:34<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 13/38: basins_mc_013.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:33<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 14/38: basins_mc_014.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:45<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 15/38: basins_mc_015.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:42<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 16/38: basins_mc_016.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:34<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 17/38: basins_mc_017.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:36<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 18/38: basins_mc_018.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:39<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 19/38: basins_mc_019.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:47<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 20/38: basins_mc_020.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 21/38: basins_mc_021.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 22/38: basins_mc_022.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:36<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 23/38: basins_mc_023.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 24/38: basins_mc_024.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 25/38: basins_mc_025.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:35<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 26/38: basins_mc_026.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:39<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 27/38: basins_mc_027.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:39<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 28/38: basins_mc_028.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:38<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 29/38: basins_mc_029.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:36<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 30/38: basins_mc_030.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:41<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 31/38: basins_mc_031.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:39<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 32/38: basins_mc_032.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:38<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 33/38: basins_mc_033.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:38<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 34/38: basins_mc_034.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 35/38: basins_mc_035.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:36<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 36/38: basins_mc_036.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:37<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 37/38: basins_mc_037.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:38<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparing run 38/38: basins_mc_038.tif ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Matching basins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 442/442 [00:39<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Wrote pixel-wise basin certainty: E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\Basins_serious\\prodem_19_MC\\basin_certainty_pixelwise.tif\n",
      "‚úì Wrote core basins based on certainty: E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\Basins_serious\\prodem_19_MC\\basins_core_pixelwise.tif\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# USER SETTINGS\n",
    "# =============================================================================\n",
    "OUT_MC = Path(r\"E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\Basins_serious\\prodem_19_MC\")\n",
    "ref_file = OUT_MC / \"basins_mc_001.tif\"   # reference realisation\n",
    "pattern  = \"basins_mc_*.tif\"              # all ensemble runs\n",
    "out_cert = OUT_MC / \"basin_certainty_pixelwise.tif\"\n",
    "out_core = OUT_MC / \"basins_core_pixelwise.tif\"\n",
    "\n",
    "OVERLAP_THRESH = 0.5   # min overlap_ratio to accept a match\n",
    "CERT_THRESH    = 0.9   # for \"core\" basins (can tweak later)\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD REFERENCE BASIN MAP\n",
    "# =============================================================================\n",
    "basin_files = sorted(f for f in OUT_MC.glob(pattern))\n",
    "if ref_file not in basin_files:\n",
    "    raise FileNotFoundError(f\"Reference file {ref_file} not found in {OUT_MC}\")\n",
    "\n",
    "# Put reference first in the list\n",
    "basin_files = [ref_file] + [f for f in basin_files if f != ref_file]\n",
    "N_runs = len(basin_files)\n",
    "print(f\"Found {N_runs} basin realisations\")\n",
    "\n",
    "with rasterio.open(ref_file) as src_ref:\n",
    "    A = src_ref.read(1)\n",
    "    meta = src_ref.meta.copy()\n",
    "    A_nodata = src_ref.nodata if src_ref.nodata is not None else 0\n",
    "    meta.update(count=1, dtype=\"float32\", nodata=0.0, compress=\"LZW\")\n",
    "    dst_transform, dst_crs = src_ref.transform, src_ref.crs\n",
    "\n",
    "maskA = (A != 0) & (A != A_nodata)\n",
    "\n",
    "# Stability counter: how many runs (including reference) consider this pixel in the \"same basin\"\n",
    "stability = np.zeros_like(A, dtype=np.uint16)\n",
    "\n",
    "# Reference run: by definition, every valid pixel matches itself\n",
    "stability[maskA] += 1\n",
    "\n",
    "# =============================================================================\n",
    "# LOOP OVER ENSEMBLE RUNS (EXCEPT REF)\n",
    "# =============================================================================\n",
    "for run_idx, basin_path in enumerate(basin_files[1:], start=2):\n",
    "    print(f\"\\n=== Comparing run {run_idx}/{N_runs}: {basin_path.name} ===\")\n",
    "\n",
    "    # --- Load and reproject B to match A's grid ---\n",
    "    with rasterio.open(basin_path) as srcB:\n",
    "        Bsrc = srcB.read(1)\n",
    "        B_nodata = srcB.nodata if srcB.nodata is not None else 0\n",
    "\n",
    "        B = np.full_like(A, B_nodata)\n",
    "        reproject(\n",
    "            source=Bsrc,\n",
    "            destination=B,\n",
    "            src_transform=srcB.transform,\n",
    "            src_crs=srcB.crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.nearest,\n",
    "            src_nodata=B_nodata,\n",
    "            dst_nodata=B_nodata,\n",
    "        )\n",
    "\n",
    "    maskB = (B != 0) & (B != B_nodata)\n",
    "\n",
    "    # For each basin ID in A, find best matching basin in B and flag overlapping pixels\n",
    "    basin_ids = np.unique(A[maskA])\n",
    "    basin_ids = basin_ids[basin_ids != 0]\n",
    "\n",
    "    # local increment map for this run: 1 where pixel is considered \"same basin\" as ref, else 0\n",
    "    same_basin_this_run = np.zeros_like(A, dtype=np.uint8)\n",
    "\n",
    "    for bid in tqdm(basin_ids, desc=\"  Matching basins\"):\n",
    "        a_mask = (A == bid)\n",
    "        area_a = np.count_nonzero(a_mask)\n",
    "        if area_a == 0:\n",
    "            continue\n",
    "\n",
    "        # overlapping basins in B within this basin of A\n",
    "        b_ids, b_counts = np.unique(B[a_mask & maskB], return_counts=True)\n",
    "        # Remove background / nodata\n",
    "        b_ids = b_ids[b_ids != 0]\n",
    "        b_counts = b_counts[b_ids != 0] if len(b_ids) > 0 else b_counts\n",
    "\n",
    "        if len(b_ids) == 0:\n",
    "            # No overlap at all ‚Üí we can't say this basin exists in this run\n",
    "            continue\n",
    "\n",
    "        best_b = b_ids[np.argmax(b_counts)]\n",
    "        overlap_best = np.count_nonzero(a_mask & (B == best_b))\n",
    "        overlap_ratio = overlap_best / area_a\n",
    "\n",
    "        if overlap_ratio >= OVERLAP_THRESH:\n",
    "            # pixels where A==bid & B==best_b are considered \"same basin\" as in ref\n",
    "            same_basin_this_run[a_mask & (B == best_b)] = 1\n",
    "        else:\n",
    "            # no dominant match ‚Üí basin considered unstable in this run\n",
    "            pass\n",
    "\n",
    "    # Update stability\n",
    "    stability += same_basin_this_run.astype(stability.dtype)\n",
    "\n",
    "# =============================================================================\n",
    "# COMPUTE PIXEL-WISE CERTAINTY\n",
    "# =============================================================================\n",
    "certainty = np.zeros_like(A, dtype=np.float32)\n",
    "certainty[maskA] = stability[maskA].astype(np.float32) / float(N_runs)\n",
    "\n",
    "# =============================================================================\n",
    "# BUILD \"CORE\" BASINS BASED ON CERTAINTY\n",
    "# =============================================================================\n",
    "# Start from reference basins; only keep high-certainty pixels\n",
    "basins_core = np.zeros_like(A, dtype=A.dtype)\n",
    "core_mask = (certainty >= CERT_THRESH) & maskA\n",
    "basins_core[core_mask] = A[core_mask]\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE OUTPUTS\n",
    "# =============================================================================\n",
    "# Certainty\n",
    "with rasterio.open(out_cert, \"w\", **meta) as dst:\n",
    "    dst.write(certainty, 1)\n",
    "print(\"‚úì Wrote pixel-wise basin certainty:\", out_cert)\n",
    "\n",
    "# Core basins\n",
    "meta_core = meta.copy()\n",
    "meta_core.update(dtype=A.dtype, nodata=0)\n",
    "with rasterio.open(out_core, \"w\", **meta_core) as dst:\n",
    "    dst.write(basins_core, 1)\n",
    "print(\"‚úì Wrote core basins based on certainty:\", out_core)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed1b8d2",
   "metadata": {},
   "source": [
    "## 3. Basin‚Äëwise stability across the ensemble\n",
    "\n",
    "This cell looks at **whole basins** rather than individual pixels:\n",
    "\n",
    "- For each basin in a reference realisation, finds matching basins in all other runs.\n",
    "- Computes an overlap‚Äëbased stability score (e.g. fraction of runs with a good match).\n",
    "- Produces maps where:\n",
    "\n",
    "  * Stable basins (high overlap across runs) can be identified.\n",
    "  * Unstable basins or those frequently split/merged across runs are highlighted.\n",
    "\n",
    "These metrics help decide which basins are robust enough to be used for subsequent\n",
    "hydrological or glaciological analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23ebf27-2720-435a-be63-774cba4c6e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 basin realisations\n",
      "\n",
      "=== Reference run 1/38: basins_mc_001.tif ===\n",
      "  ‚Üí max cluster size for this ref: 38\n",
      "\n",
      "=== Reference run 2/38: basins_mc_002.tif ===\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.7 MiB for an array with shape (5539, 3163) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 92\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# What B-basins overlap this A-basin?\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m vals \u001b[38;5;241m=\u001b[39m B[\u001b[43ma_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmaskB\u001b[49m]\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vals\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# this basin doesn't exist in this run at all\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.7 MiB for an array with shape (5539, 3163) and data type bool"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# USER SETTINGS\n",
    "# =============================================================================\n",
    "MC_DIR   = Path(r\"E:\\Rasmus\\DTU\\Cryo\\4DGreenland\\Basins_serious\\prodem_19_MC\")\n",
    "pattern  = \"basins_mc_*.tif\"      # all ensemble realisations\n",
    "OVERLAP_THRESH = 0.5              # min overlap ratio to accept a basin match\n",
    "CERT_THRESH    = 0.9              # for \"core\" basins (can tweak later)\n",
    "\n",
    "out_cert = MC_DIR / \"basin_certainty_allruns.tif\"\n",
    "out_core = MC_DIR / \"basins_core_allruns.tif\"\n",
    "\n",
    "# =============================================================================\n",
    "# COLLECT FILES\n",
    "# =============================================================================\n",
    "basin_files = sorted(MC_DIR.glob(pattern))\n",
    "if not basin_files:\n",
    "    raise FileNotFoundError(f\"No files matching {pattern} in {MC_DIR}\")\n",
    "\n",
    "N_runs = len(basin_files)\n",
    "print(f\"Found {N_runs} basin realisations\")\n",
    "\n",
    "# Use first file as template for grid / metadata\n",
    "with rasterio.open(basin_files[0]) as src0:\n",
    "    template = src0.read(1)\n",
    "    meta = src0.meta.copy()\n",
    "    A0_nodata = src0.nodata if src0.nodata is not None else 0\n",
    "    meta.update(count=1, dtype=\"float32\", nodata=0.0, compress=\"LZW\")\n",
    "\n",
    "nrows, ncols = template.shape\n",
    "\n",
    "# This will hold, for each pixel, the largest cluster size found over all references\n",
    "best_cluster = np.zeros_like(template, dtype=np.uint16)\n",
    "\n",
    "# We'll treat any non-zero, non-nodata value as \"valid basin\"\n",
    "global_valid_mask = np.zeros_like(template, dtype=bool)\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN DOUBLE LOOP: EACH RUN AS REFERENCE\n",
    "# =============================================================================\n",
    "for j, ref_path in enumerate(basin_files):\n",
    "    print(f\"\\n=== Reference run {j+1}/{N_runs}: {ref_path.name} ===\")\n",
    "\n",
    "    # --- Load reference basins ---\n",
    "    with rasterio.open(ref_path) as src_ref:\n",
    "        A = src_ref.read(1)\n",
    "        A_nodata = src_ref.nodata if src_ref.nodata is not None else 0\n",
    "\n",
    "        # sanity check: same grid / CRS\n",
    "        if src_ref.width != meta[\"width\"] or src_ref.height != meta[\"height\"]:\n",
    "            raise ValueError(f\"Grid size mismatch in {ref_path}\")\n",
    "        if src_ref.transform != meta[\"transform\"]:\n",
    "            raise ValueError(f\"Transform mismatch in {ref_path}\")\n",
    "        if src_ref.crs != meta[\"crs\"]:\n",
    "            raise ValueError(f\"CRS mismatch in {ref_path}\")\n",
    "\n",
    "    maskA = (A != 0) & (A != A_nodata)\n",
    "    global_valid_mask |= maskA\n",
    "\n",
    "    # cluster size anchored at this reference:\n",
    "    # start with 1 where A has a basin (this run itself)\n",
    "    cluster = np.zeros_like(A, dtype=np.uint16)\n",
    "    cluster[maskA] = 1\n",
    "\n",
    "    # IDs of basins in this reference\n",
    "    basin_ids = np.unique(A[maskA])\n",
    "    basin_ids = basin_ids[basin_ids != 0]\n",
    "\n",
    "    # --- Loop over all OTHER runs and compare to this reference ---\n",
    "    for k, other_path in enumerate(basin_files):\n",
    "        if k == j:\n",
    "            continue\n",
    "\n",
    "        with rasterio.open(other_path) as srcB:\n",
    "            B = srcB.read(1)\n",
    "            B_nodata = srcB.nodata if srcB.nodata is not None else 0\n",
    "\n",
    "        maskB = (B != 0) & (B != B_nodata)\n",
    "\n",
    "        # For each basin in the reference\n",
    "        for bid in basin_ids:\n",
    "            a_mask = (A == bid)\n",
    "            area_a = np.count_nonzero(a_mask)\n",
    "            if area_a == 0:\n",
    "                continue\n",
    "\n",
    "            # What B-basins overlap this A-basin?\n",
    "            vals = B[a_mask & maskB]\n",
    "            if vals.size == 0:\n",
    "                # this basin doesn't exist in this run at all\n",
    "                continue\n",
    "\n",
    "            b_ids, counts = np.unique(vals, return_counts=True)\n",
    "            # Remove background if present\n",
    "            valid_idx = (b_ids != 0)\n",
    "            b_ids = b_ids[valid_idx]\n",
    "            counts = counts[valid_idx]\n",
    "\n",
    "            if len(b_ids) == 0:\n",
    "                continue\n",
    "\n",
    "            # Best-matching B basin by area overlap\n",
    "            best_b = b_ids[np.argmax(counts)]\n",
    "            overlap_mask = a_mask & (B == best_b)\n",
    "            overlap_best = np.count_nonzero(overlap_mask)\n",
    "            overlap_ratio = overlap_best / area_a\n",
    "\n",
    "            if overlap_ratio >= OVERLAP_THRESH:\n",
    "                # These pixels are \"same basin\" in run k as in reference j\n",
    "                cluster[overlap_mask] += 1\n",
    "\n",
    "    # Update global best cluster size\n",
    "    best_cluster = np.maximum(best_cluster, cluster)\n",
    "    print(f\"  ‚Üí max cluster size for this ref: {cluster.max()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPUTE PIXEL-WISE CERTAINTY\n",
    "# =============================================================================\n",
    "certainty = np.zeros_like(template, dtype=np.float32)\n",
    "certainty[global_valid_mask] = (\n",
    "    best_cluster[global_valid_mask].astype(np.float32) / float(N_runs)\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# BUILD \"CORE\" BASINS (OPTIONAL)\n",
    "# =============================================================================\n",
    "# For a core-product, we still need *some* basin labels.\n",
    "# Easiest symmetric choice: take the MODE (most frequent) basin ID across all runs,\n",
    "# then only keep it where certainty >= CERT_THRESH.\n",
    "\n",
    "# Load all basins into memory (may need RAM if domain is large and N_runs big)\n",
    "print(\"\\nLoading stack of basins to compute consensus labels...\")\n",
    "stack = np.zeros((N_runs, nrows, ncols), dtype=template.dtype)\n",
    "for i, fpath in enumerate(basin_files):\n",
    "    with rasterio.open(fpath) as src:\n",
    "        stack[i] = src.read(1)\n",
    "\n",
    "consensus_basins = np.zeros_like(template, dtype=template.dtype)\n",
    "core_mask = (certainty >= CERT_THRESH) & global_valid_mask\n",
    "\n",
    "# Compute per-pixel mode label only where we care (core_mask)\n",
    "print(\"Computing mode label for high-certainty pixels (this can take a bit)...\")\n",
    "rows, cols = np.where(core_mask)\n",
    "for r, c in tqdm(zip(rows, cols), total=len(rows), desc=\"  Mode per pixel\"):\n",
    "    vals = stack[:, r, c]\n",
    "    vals = vals[vals != 0]  # ignore background\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    labels, counts = np.unique(vals, return_counts=True)\n",
    "    consensus_basins[r, c] = labels[np.argmax(counts)]\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE OUTPUTS\n",
    "# =============================================================================\n",
    "# Certainty map\n",
    "with rasterio.open(out_cert, \"w\", **meta) as dst:\n",
    "    dst.write(certainty, 1)\n",
    "print(\"‚úì Wrote pixel-wise basin certainty:\", out_cert)\n",
    "\n",
    "# Core basins map\n",
    "meta_core = meta.copy()\n",
    "meta_core.update(dtype=template.dtype, nodata=0)\n",
    "with rasterio.open(out_core, \"w\", **meta_core) as dst:\n",
    "    dst.write(consensus_basins, 1)\n",
    "print(\"‚úì Wrote core basins based on all-run certainty:\", out_core)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d1032",
   "metadata": {},
   "source": [
    "## 4. (Optional) Extra analysis\n",
    "\n",
    "Use this cell for plotting histograms of certainty, exploring thresholds,\n",
    "or exporting summary tables for specific outlet basins of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc74968-5579-4b21-a822-173be469ceb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
